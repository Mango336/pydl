{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5570,  1.1372, -0.8584],\n",
      "        [ 0.5830, -0.2161,  0.2341],\n",
      "        [-0.3955,  1.7814,  0.4831],\n",
      "        [-0.7377, -2.1611, -0.5787],\n",
      "        [-0.2872,  0.8691,  1.2738]])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n",
      "tensor([[0.6721, 0.6937, 0.9878],\n",
      "        [0.7342, 0.9997, 0.8603],\n",
      "        [0.6252, 0.6797, 0.5926],\n",
      "        [0.6243, 0.7581, 0.3048],\n",
      "        [0.4615, 0.4275, 0.5854]])\n",
      "tensor([[ 1.2291,  1.8310,  0.1295],\n",
      "        [ 1.3172,  0.7836,  1.0944],\n",
      "        [ 0.2298,  2.4611,  1.0757],\n",
      "        [-0.1134, -1.4029, -0.2738],\n",
      "        [ 0.1743,  1.2965,  1.8593]])\n",
      "tensor([[ 1.2291,  1.8310,  0.1295],\n",
      "        [ 1.3172,  0.7836,  1.0944],\n",
      "        [ 0.2298,  2.4611,  1.0757],\n",
      "        [-0.1134, -1.4029, -0.2738],\n",
      "        [ 0.1743,  1.2965,  1.8593]])\n",
      "tensor([[ 1.2291,  1.8310,  0.1295],\n",
      "        [ 1.3172,  0.7836,  1.0944],\n",
      "        [ 0.2298,  2.4611,  1.0757],\n",
      "        [-0.1134, -1.4029, -0.2738],\n",
      "        [ 0.1743,  1.2965,  1.8593]])\n",
      "tensor([[ 1.2291,  1.8310,  0.1295],\n",
      "        [ 1.3172,  0.7836,  1.0944],\n",
      "        [ 0.2298,  2.4611,  1.0757],\n",
      "        [-0.1134, -1.4029, -0.2738],\n",
      "        [ 0.1743,  1.2965,  1.8593]])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "torch基础语法\n",
    "'''\n",
    "import torch\n",
    "import numpy\n",
    "# torch创建\n",
    "x = torch.randn(5, 3)\n",
    "print(x)\n",
    "y = torch.rand(5, 3)\n",
    "# torch的形状\n",
    "print(y.size())\n",
    "print(y.shape)\n",
    "print(y)\n",
    "# 加法的表示形式： 四种\n",
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "\n",
    "y.add_(x)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2291,  1.8310,  0.1295],\n",
      "        [ 1.3172,  0.7836,  1.0944],\n",
      "        [ 0.2298,  2.4611,  1.0757],\n",
      "        [-0.1134, -1.4029, -0.2738],\n",
      "        [ 0.1743,  1.2965,  1.8593]])\n",
      "tensor([[ 2.2291,  2.8310,  1.1295],\n",
      "        [ 2.3172,  1.7836,  2.0944],\n",
      "        [ 1.2298,  3.4611,  2.0757],\n",
      "        [ 0.8866, -0.4029,  0.7262],\n",
      "        [ 1.1743,  2.2965,  2.8593]])\n",
      "tensor([[ 1.2291,  1.8310,  0.1295],\n",
      "        [ 1.3172,  0.7836,  1.0944],\n",
      "        [ 0.2298,  2.4611,  1.0757],\n",
      "        [-0.1134, -1.4029, -0.2738],\n",
      "        [ 0.1743,  1.2965,  1.8593]])\n"
     ]
    }
   ],
   "source": [
    "# copy torch => copy出来的跟原数组共享内存\n",
    "b = torch.empty(5, 3)\n",
    "b.copy_(y)\n",
    "print(b)\n",
    "# 若想要不共享内存 用clone\n",
    "y_cp = y.clone()\n",
    "y_cp += 1\n",
    "print(y_cp)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3530]) 0.3530401587486267\n"
     ]
    }
   ],
   "source": [
    "# item()函数 将torch转换为python number\n",
    "# 并且only one element tensors can be converted to Python scalars\n",
    "i = torch.rand(1)\n",
    "print(i, i.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5570,  1.1372, -0.8584],\n",
      "        [ 0.5830, -0.2161,  0.2341],\n",
      "        [-0.3955,  1.7814,  0.4831],\n",
      "        [-0.7377, -2.1611, -0.5787],\n",
      "        [-0.2872,  0.8691,  1.2738]])\n",
      "tensor([[ 0.5570,  0.5830, -0.3955, -0.7377, -0.2872],\n",
      "        [ 1.1372, -0.2161,  1.7814, -2.1611,  0.8691],\n",
      "        [-0.8584,  0.2341,  0.4831, -0.5787,  1.2738]])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵转置\n",
    "print(x)\n",
    "print(x.T)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5570,  1.1372, -0.8584])\n",
      "tensor([1.5570, 2.1372, 0.1416])\n",
      "tensor([1.5570, 2.1372, 0.1416])\n"
     ]
    }
   ],
   "source": [
    "# 索引出来的结果与原数据共享内存 修改一个，另一个也会改变\n",
    "y = x[0, :]\n",
    "print(x[0, :])\n",
    "y += 1\n",
    "print(y)\n",
    "print(x[0, :])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3]) torch.Size([15])\n",
      "tensor(0.1893) tensor(0.1893)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "y = x.view(15)\n",
    "print(x.size(), y.size())\n",
    "print(x[0, 0], y[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "# 广播机制\n",
    "x = torch.arange(1, 3).view(1, 2)\n",
    "print(x)\n",
    "y = torch.arange(1, 4).view(3, 1)\n",
    "print(y)\n",
    "print(x + y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "y[:] = x + y\n",
    "print(id_before == id(y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a, b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "[3. 3. 3. 3. 3.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
      "[4. 4. 4. 4. 4.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = numpy.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a, b)\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)\n",
    "\n",
    "c = torch.tensor(a)\n",
    "a += 1\n",
    "print(a, c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x, device=device)\n",
    "    x = x.to(device)\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))\n",
    "else:\n",
    "    print(\"none\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "None\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x0000021B349F61F0>\n",
      "True False\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "print(x.grad_fn)\n",
    "y = x + 2\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "print(x.is_leaf, y.is_leaf)\n",
    "\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "a leaf:  True\n",
      "b leaf:  False\n",
      "True\n",
      "c leaf:  False\n",
      "c grad:  True\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad) # False\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "print(\"a leaf: \", a.is_leaf)\n",
    "# b = torch.randn(2, 2)\n",
    "b = (a * 3)\n",
    "b.requires_grad_(True)\n",
    "print(\"b leaf: \", b.is_leaf)\n",
    "print(b.requires_grad)\n",
    "\n",
    "c = a + 1\n",
    "print(\"c leaf: \", c.is_leaf)\n",
    "print(\"c grad: \", c.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "<AddBackward0 object at 0x0000021B343B9190>\n",
      "tensor([[  1.3433,  21.6519],\n",
      "        [-29.7750,  26.9980]], grad_fn=<AddBackward0>)\n",
      "a:  tensor([[4., 4.],\n",
      "        [4., 4.]])\n",
      "b:  None\n",
      "2315863586176 2315865712000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-75-bdd13eb4d42d>:8: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  print(\"b: \", b.grad)\n"
     ]
    }
   ],
   "source": [
    "c = a + b\n",
    "print(c.is_leaf)\n",
    "print(c.grad_fn)\n",
    "print(c)\n",
    "c = c.sum()\n",
    "c.backward()\n",
    "print(\"a: \", a.grad)\n",
    "print(\"b: \", b.grad)\n",
    "\n",
    "print(id(a), id(b))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 6.0892,  6.2531],\n        [ 0.3503, -0.2356]])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}